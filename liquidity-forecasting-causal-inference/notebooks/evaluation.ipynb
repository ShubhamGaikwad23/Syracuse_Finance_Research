{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171463ed",
   "metadata": {},
   "source": [
    "SARIMA Evaluation: AIC, BIC, MAPE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af588d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#SARIMA Evaluation: AIC, BIC, MAPE, MAE\n",
    "\n",
    "from statsmodels.tools.eval_measures import mse, meanabs\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Assume you have a SARIMA results model and test data\n",
    "# Let's split last 30 days for testing\n",
    "train = df['liquidity'][:-30]\n",
    "test = df['liquidity'][-30:]\n",
    "\n",
    "# Refit model on training\n",
    "from src.sarima_model import train_sarima\n",
    "sarima_model = train_sarima(train)\n",
    "\n",
    "# Forecast\n",
    "forecast = sarima_model.get_forecast(steps=30).predicted_mean\n",
    "\n",
    "# Evaluation metrics\n",
    "aic = sarima_model.aic\n",
    "bic = sarima_model.bic\n",
    "mape = mean_absolute_percentage_error(test, forecast)\n",
    "mae = meanabs(test, forecast)\n",
    "\n",
    "print(\"SARIMA Evaluation:\")\n",
    "print(f\"AIC: {aic:.2f}\")\n",
    "print(f\"BIC: {bic:.2f}\")\n",
    "print(f\"MAPE: {mape:.4f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2914b16e",
   "metadata": {},
   "source": [
    "SARIMA Evaluation: AIC, BIC, MAPE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56757213",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "from src.xgboost_model import prepare_features, train_xgb\n",
    "\n",
    "df_feat = prepare_features(df.copy())\n",
    "\n",
    "X = df_feat[[f'lag_{i}' for i in range(1, 6)]]\n",
    "y = df_feat['liquidity']\n",
    "\n",
    "# Simple 80/20 split\n",
    "split_idx = int(0.8 * len(df_feat))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Train and predict\n",
    "xgb_model = train_xgb(pd.concat([X_train, y_train], axis=1))\n",
    "preds = xgb_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "print(\"\\nXGBoost Evaluation:\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23dc82",
   "metadata": {},
   "source": [
    " Difference-in-Differences (DiD) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928b12f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.causal_inference import run_did\n",
    "\n",
    "# Already contains 'event', 'treated', 'interaction'\n",
    "did_model = run_did(df.copy())\n",
    "\n",
    "# Look at p-value for the interaction term\n",
    "interaction_pval = did_model.pvalues['interaction']\n",
    "interaction_coef = did_model.params['interaction']\n",
    "\n",
    "print(\"\\nDiD Evaluation:\")\n",
    "print(f\"Interaction Coefficient: {interaction_coef:.2f}\")\n",
    "print(f\"p-value: {interaction_pval:.4f}\")\n",
    "if interaction_pval < 0.05:\n",
    "    print(\"✅ Statistically significant impact of market event on liquidity.\")\n",
    "else:\n",
    "    print(\"❌ No statistically significant impact.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
